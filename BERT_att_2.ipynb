{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "abc29a24-5a8c-4606-a159-6b33eee87b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "df_credb = pd.read_excel('createDebate.xlsx')\n",
    "df_credb = df_credb.query(\"stance == 'prefers strict gun control' | stance == 'opposes strict gun control'\")\n",
    "df_credb = df_credb[[\"text\", \"stance\"]]\n",
    "#Encoding the stance, which is our target class\n",
    "import numpy as np\n",
    "\n",
    "if type(df_credb.stance.iloc[1]) is str:\n",
    "    class_mapping = {label: idx for idx, label in \n",
    "                    enumerate(np.unique(df_credb['stance']))}\n",
    "#Prevents accidentally overwriting the \n",
    "if type(df_credb.stance.iloc[1]) is str:\n",
    "    df_credb['stance'] = df_credb['stance'].map(class_mapping)\n",
    "    \n",
    "oppose = df_credb.query(\"stance == 0\")\n",
    "support = df_credb.query(\"stance == 1\")\n",
    "\n",
    "oppose = oppose[:100]\n",
    "support = support[:100]\n",
    "\n",
    "df_reduced = pd.concat([support,oppose])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e4fd8eb1-c95a-4e82-b215-e14a51a00941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the BERT model and tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "\n",
    "if 'bertModel' not in locals() or 'tokenizer' not in locals():\n",
    "    #BERT base model\n",
    "    bertModel = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    #BERT Tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "820c9ec6-3176-4431-8c68-719ea81705dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some example data\n",
    "texts = df_credb.text.values.tolist()\n",
    "labels = df_credb.stance.values.tolist()\n",
    "\n",
    "#tokenize the texts\n",
    "tokens = tokenizer(texts, padding=True, truncation=True, return_tensors='np') #Use Tensorflow for faster training\n",
    "\n",
    "#Create dict of tokenized data\n",
    "tokenized_data = dict(tokens)\n",
    "\n",
    "#Encode labels as a numpy array\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "50309eed-3ff1-4356-ab79-b304ec6b9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer for the model\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = tf.keras.layers.Input(shape=(512,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "bert_layer = bertModel({'input_ids': input_ids, 'attention_mask': attention_mask})[0]\n",
    "\n",
    "# Add a GlobalMaxPooling1D layer to reduce the sequence length dimension to 1\n",
    "pooled_output = tf.keras.layers.GlobalMaxPooling1D()(bert_layer)\n",
    "\n",
    "dropout = tf.keras.layers.Dropout(0.1, name=\"dropout\")(pooled_output)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(1,activation='sigmoid')(dropout)\n",
    "\n",
    "'''dense_layer_2 = tf.keras.layers.Dense(256,activation='relu')(dense_layer_1)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(2,activation='sigmoid')(dense_layer_2)'''\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output_layer)\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(optimizer=Adam(3e-5),\n",
    "                 loss = 'mean_squared_error',\n",
    "                 metrics = METRICS)\n",
    "\n",
    "\n",
    "#model.fit(tokenized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "424abe1a-2055-4e96-9a9c-452ba33a1ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    multiple             109482240   ['attention_mask[0][0]',         \n",
      "                                                                  'input_ids[0][0]']              \n",
      "                                                                                                  \n",
      " global_max_pooling1d_17 (Globa  (None, 768)         0           ['tf_bert_model[31][0]']         \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['global_max_pooling1d_17[0][0]']\n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,009\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4c173226-4b60-4d98-bb3e-2654098cb1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x32dd868b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x32dd868b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/einsteinium/opt/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py:638: UserWarning: Input dict contained keys ['token_type_ids'] which did not match any model input. They will be ignored by the model.\n",
      "  if mask is None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 2196s 6s/step - loss: 0.2806 - accuracy: 0.4923 - precision: 0.4936 - recall: 0.5913\n",
      "Epoch 2/2\n",
      "382/382 [==============================] - 2259s 6s/step - loss: 0.2695 - accuracy: 0.5046 - precision: 0.5047 - recall: 0.4926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c6fa4bb0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tokenized_data, labels, batch_size=16, epochs=2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212bbe1f-d206-4a19-b4a3-efb0d519c0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
