{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bert-for-tf2 in c:\\users\\henry\\appdata\\roaming\\python\\python310\\site-packages (0.14.9)\n",
      "Requirement already satisfied: py-params>=0.9.6 in c:\\users\\henry\\appdata\\roaming\\python\\python310\\site-packages (from bert-for-tf2) (0.10.2)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in c:\\users\\henry\\appdata\\roaming\\python\\python310\\site-packages (from bert-for-tf2) (0.8.2)\n",
      "Requirement already satisfied: numpy in c:\\program files\\python310\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.23.5)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python310\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python310\\lib\\site-packages (from tqdm->params-flow>=0.8.0->bert-for-tf2) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\henry\\appdata\\roaming\\python\\python310\\site-packages (0.1.98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2\n",
    "!pip install sentencepiece"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\henry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub    # imports the weights, call of bert\n",
    "\n",
    "from tensorflow.python.keras import layers\n",
    "import bert\n",
    "import nltk\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer model\n",
    "\n",
    "from nltk.tokenize import sent_tokenize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "unknown                       3051\nprefers strict gun control    3051\nopposes strict gun control    3051\nundecided                     3051\nother                         3051\nName: stance, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataframe from createDebate.xlsx with headers\n",
    "df_createDebate = pd.read_excel('createDebate.xlsx', header=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "columns_to_keep = ['stance', 'text']\n",
    "data = df_createDebate.filter(columns_to_keep)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text input, remove insignificant parts\n",
    "    :param text: text input\n",
    "    :return: clean text\n",
    "    \"\"\"\n",
    "    # Keep only the plain text and meaningful punctuations.\n",
    "    text = re.sub(r\"[^a-zA-Z.!?']\", ' ', text)\n",
    "    # Remove additional spaces.\n",
    "    text = re.sub(r\" +\", ' ', text)\n",
    "    return text\n",
    "\n",
    "def sep_sentences(text):\n",
    "    \"\"\"\n",
    "    Seperate sentences\n",
    "    :param text: the plain text input\n",
    "    :return: a list of sentences from the text\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "# text = \"Hello** Jona, this is Michael! You're so nice. I hate going out with Your friends.\"\n",
    "# text = clean_text(text)\n",
    "# li = sep_sentences(text)\n",
    "# print(li)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "data_clean = [clean_text(text) for text in data.text]    # Clean the text\n",
    "data_sent = [sep_sentences(text) for text in data_clean]    # Seperate the sentences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "data_stance = data.stance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def encode_sentence(sent):\n",
    "    \"\"\"\n",
    "    Encode the sentence. Add [CLS] and [SEP] labels to the tokenized sentence just so BERT would understand.\n",
    "    :param sent: the sentence to be encoded\n",
    "    :return: encoded sentence\n",
    "    \"\"\"\n",
    "    return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# encode every sentence from data_sent\n",
    "data_inputs = [\n",
    "    [encode_sentence(sent) for sent in text] for text in data_sent\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'guns', 'provide', 'a', 'trigger', 'for', 'any', 'violent', 'activity', 'in', 'the', 'society', 'like', 'the', 'virginia', 'university', 'incident', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "# print(data_inputs[1][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Author: Martin J. et al.\n",
    "# Link: https://colab.research.google.com/drive/1jMin0iXmW4ZrSlwjhj2xJAiCrUMOLsqg?usp=sharing\n",
    "def get_ids(tokens):\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def get_mask(tokens):\n",
    "    return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
    "\n",
    "def get_segments(tokens):\n",
    "    seg_ids = []\n",
    "    current_seg_id = 0\n",
    "    for tok in tokens:\n",
    "        seg_ids.append(current_seg_id)\n",
    "        if tok == \"[SEP]\":\n",
    "            current_seg_id = 1-current_seg_id # convert 1 into 0 and vice versa\n",
    "    return seg_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Data output (Maybe?)\n",
    "stance_output = [encode_sentence(sentence) for sentence in data_stance]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Establish the length-data relationship for shuffling\n",
    "data_len = [[text, stance_output[i], len(text)] for i, text in enumerate(data_inputs)]\n",
    "random.shuffle(data_len)\n",
    "\n",
    "# Sort accroding to how many sentences are there in each text string.\n",
    "data_len.sort(key=lambda x: x[2])\n",
    "# Only take the texts with 2 or more sentences into account.\n",
    "sorted_all = [(sent_lab[0], sent_lab[1]) for sent_lab in data_len if sent_lab[2] >= 2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all, output_types=(tf.int32, tf.int32))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [['[CLS]', 'guns', 'should', 'be', 'banned', '.', '[SEP]'], ['[CLS]', 'guns', 'are', 'meant', 'to', 'protect', 'not', 'kill', 'but', 'in', 'the', 'last', 'few', 'days', 'we', 'are', 'seeing', 'people', 'killing', 'each', 'other', '[SEP]']].\nTraceback (most recent call last):\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 214, in generator_py_func\n    script_ops.FuncRegistry._convert(  # pylint: disable=protected-access\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 226, in _convert\n    result = np.asarray(value, dtype=dtype, order=\"C\")\n\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 218, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [['[CLS]', 'guns', 'should', 'be', 'banned', '.', '[SEP]'], ['[CLS]', 'guns', 'are', 'meant', 'to', 'protect', 'not', 'kill', 'but', 'in', 'the', 'last', 'few', 'days', 'we', 'are', 'seeing', 'people', 'killing', 'each', 'other', '[SEP]']].\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mall_dataset\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:797\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    796\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 797\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    798\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:780\u001B[0m, in \u001B[0;36mOwnedIterator._next_internal\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001B[39;00m\n\u001B[0;32m    778\u001B[0m \u001B[38;5;66;03m# to communicate that there is no more data to iterate over.\u001B[39;00m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecution_mode(context\u001B[38;5;241m.\u001B[39mSYNC):\n\u001B[1;32m--> 780\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator_get_next\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    782\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    783\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    785\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001B[39;00m\n\u001B[0;32m    787\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec\u001B[38;5;241m.\u001B[39m_from_compatible_tensor_list(ret)  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3043\u001B[0m, in \u001B[0;36miterator_get_next\u001B[1;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[0;32m   3041\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   3042\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 3043\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3044\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[0;32m   3045\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7261\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7262\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [['[CLS]', 'guns', 'should', 'be', 'banned', '.', '[SEP]'], ['[CLS]', 'guns', 'are', 'meant', 'to', 'protect', 'not', 'kill', 'but', 'in', 'the', 'last', 'few', 'days', 'we', 'are', 'seeing', 'people', 'killing', 'each', 'other', '[SEP]']].\nTraceback (most recent call last):\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 214, in generator_py_func\n    script_ops.FuncRegistry._convert(  # pylint: disable=protected-access\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 226, in _convert\n    result = np.asarray(value, dtype=dtype, order=\"C\")\n\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Program Files\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 218, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [['[CLS]', 'guns', 'should', 'be', 'banned', '.', '[SEP]'], ['[CLS]', 'guns', 'are', 'meant', 'to', 'protect', 'not', 'kill', 'but', 'in', 'the', 'last', 'few', 'days', 'we', 'are', 'seeing', 'people', 'killing', 'each', 'other', '[SEP]']].\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "next(iter(all_dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
